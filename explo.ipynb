{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yR6H04Fk9lf"
   },
   "source": [
    "### Run the below for installing the packages and using it\n",
    "- Remove the hashes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Io2OsK9Tk2b-"
   },
   "outputs": [],
   "source": [
    "# pip install numpy==1.22.4\n",
    "# pip install pandas==1.5.3\n",
    "# pip install scikit-learn==1.2.2\n",
    "# pip install keras==2.12.0\n",
    "# pip install tensorflow==2.12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKJvxSf9lOn-"
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cySy-fVJ9eaJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zw3YrQbalRal"
   },
   "source": [
    "### Load Dataset\n",
    "- Give the appropriate file path to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WROFjY6y9m3f"
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"C:\\\\Users\\\\DELL\\Downloads\\\\harshita explo1.xlsx\") # change the path to the excel file as per your filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "mxjtN-8qjJcC",
    "outputId": "8da656a5-f8ea-4f62-c889-b3eb75b999e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Laser power(W)</th>\n",
       "      <th>Traverse feed(mm/s)</th>\n",
       "      <th>Hatch Spacing(μm)</th>\n",
       "      <th>Layer thickness(μm)</th>\n",
       "      <th>Build direction</th>\n",
       "      <th>Yield strength (MPa)</th>\n",
       "      <th>Ultimate tensile strength (MPa)</th>\n",
       "      <th>Total elongation (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>500</td>\n",
       "      <td>200.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>240</td>\n",
       "      <td>500</td>\n",
       "      <td>200.0</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>220.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>960</td>\n",
       "      <td>1100</td>\n",
       "      <td>200.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>960</td>\n",
       "      <td>1100</td>\n",
       "      <td>200.0</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>204.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>1000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Laser power(W)  Traverse feed(mm/s)  Hatch Spacing(μm)  \\\n",
       "0           1             240                  500              200.0   \n",
       "1           2             240                  500              200.0   \n",
       "2           3             960                 1100              200.0   \n",
       "3           4             960                 1100              200.0   \n",
       "4           5             380                 1000              100.0   \n",
       "\n",
       "   Layer thickness(μm)  Build direction  Yield strength (MPa)  \\\n",
       "0                   50                0                 245.0   \n",
       "1                   50               90                 220.0   \n",
       "2                   50                0                 232.0   \n",
       "3                   50               90                 204.0   \n",
       "4                   30                0                 280.0   \n",
       "\n",
       "   Ultimate tensile strength (MPa)  Total elongation (%)  \n",
       "0                            420.0                   5.9  \n",
       "1                            400.0                   3.2  \n",
       "2                            415.0                   8.0  \n",
       "3                            437.0                   5.5  \n",
       "4                            472.0                   7.8  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HVv0wjGi96yI"
   },
   "outputs": [],
   "source": [
    "data = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "ft_EV-1KjPGZ",
    "outputId": "57f95d38-b8c2-47fd-a47f-b0b0ab860c9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laser power(W)</th>\n",
       "      <th>Traverse feed(mm/s)</th>\n",
       "      <th>Hatch Spacing(μm)</th>\n",
       "      <th>Layer thickness(μm)</th>\n",
       "      <th>Build direction</th>\n",
       "      <th>Yield strength (MPa)</th>\n",
       "      <th>Ultimate tensile strength (MPa)</th>\n",
       "      <th>Total elongation (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240</td>\n",
       "      <td>500</td>\n",
       "      <td>200.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240</td>\n",
       "      <td>500</td>\n",
       "      <td>200.0</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>220.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>960</td>\n",
       "      <td>1100</td>\n",
       "      <td>200.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>960</td>\n",
       "      <td>1100</td>\n",
       "      <td>200.0</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>204.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>380</td>\n",
       "      <td>1000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Laser power(W)  Traverse feed(mm/s)  Hatch Spacing(μm)  \\\n",
       "0             240                  500              200.0   \n",
       "1             240                  500              200.0   \n",
       "2             960                 1100              200.0   \n",
       "3             960                 1100              200.0   \n",
       "4             380                 1000              100.0   \n",
       "\n",
       "   Layer thickness(μm)  Build direction  Yield strength (MPa)  \\\n",
       "0                   50                0                 245.0   \n",
       "1                   50               90                 220.0   \n",
       "2                   50                0                 232.0   \n",
       "3                   50               90                 204.0   \n",
       "4                   30                0                 280.0   \n",
       "\n",
       "   Ultimate tensile strength (MPa)  Total elongation (%)  \n",
       "0                            420.0                   5.9  \n",
       "1                            400.0                   3.2  \n",
       "2                            415.0                   8.0  \n",
       "3                            437.0                   5.5  \n",
       "4                            472.0                   7.8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qDdEecMGRyu",
    "outputId": "e3be2bbd-f2cd-48fb-83ba-f97d944229b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Laser power(W)                   52 non-null     int64  \n",
      " 1   Traverse feed(mm/s)              52 non-null     int64  \n",
      " 2   Hatch Spacing(μm)                52 non-null     float64\n",
      " 3   Layer thickness(μm)              52 non-null     int64  \n",
      " 4   Build direction                  52 non-null     int64  \n",
      " 5   Yield strength (MPa)             52 non-null     float64\n",
      " 6   Ultimate tensile strength (MPa)  52 non-null     float64\n",
      " 7   Total elongation (%)             52 non-null     float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 3.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8tsNzZUHbCf"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1j_Lf5-jEmUY"
   },
   "outputs": [],
   "source": [
    "X = data[['Laser power(W)','Traverse feed(mm/s)','Hatch Spacing(μm)','Layer thickness(μm)','Build direction']]\n",
    "y = data[['Yield strength (MPa)','Ultimate tensile strength (MPa)','Total elongation (%)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPlEA0UVHgKn"
   },
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OrjSplvNF4eX"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5KwWMF0mF7lf"
   },
   "outputs": [],
   "source": [
    "LR_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "xnBgI-8GGJoA",
    "outputId": "716ee359-cded-4d73-bcf3-8698d9899a32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IlebtSbJGOuC"
   },
   "outputs": [],
   "source": [
    "predictions = LR_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91MuuG7IHzwo",
    "outputId": "34930898-677b-4dc6-dd9e-687ede662259"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[247.37607831, 364.1675412 ,   6.21915909],\n",
       "       [225.3076385 , 356.70612613,   4.52918943],\n",
       "       [230.99570759, 445.26115208,   9.41833675],\n",
       "       [208.92726779, 437.79973701,   7.72836709],\n",
       "       [263.22043511, 426.77064174,   7.26481269],\n",
       "       [241.15199531, 419.30922667,   5.57484303],\n",
       "       [233.76356701, 362.80664557,   7.27722623],\n",
       "       [211.6951272 , 355.34523051,   5.58725657],\n",
       "       [256.71619894, 429.56033113,   7.27871278],\n",
       "       [234.64775914, 422.09891607,   5.58874312],\n",
       "       [254.94204967, 427.3908241 ,   7.39920688],\n",
       "       [232.87360987, 419.92940903,   5.70923722],\n",
       "       [255.83895829, 426.07988299,   7.2886091 ],\n",
       "       [233.77051848, 418.61846793,   5.59863944],\n",
       "       [255.3086803 , 424.94989196,   7.31468718],\n",
       "       [233.2402405 , 417.48847689,   5.62471752],\n",
       "       [261.81291647, 422.16020256,   7.30078709],\n",
       "       [239.74447667, 414.6987875 ,   5.61081744],\n",
       "       [258.15549543, 416.69419826,   7.31217405],\n",
       "       [236.08705563, 409.2327832 ,   5.6222044 ],\n",
       "       [245.24749321, 371.80381006,   6.79151984],\n",
       "       [223.1790534 , 364.342395  ,   5.10155018],\n",
       "       [255.13593334, 421.59845923,   7.18945209],\n",
       "       [233.06749354, 414.13704417,   5.49948243],\n",
       "       [259.64483775, 423.09009903,   7.30542046],\n",
       "       [237.57639794, 415.62868396,   5.6154508 ],\n",
       "       [254.75873435, 428.61129017,   7.44146673],\n",
       "       [232.69029455, 421.1498751 ,   5.75149707],\n",
       "       [227.18017052, 379.55294728,   6.83013119],\n",
       "       [205.11173071, 372.09153221,   5.14016153],\n",
       "       [244.08088164, 369.31782979,   6.84889162],\n",
       "       [222.01244183, 361.85641472,   5.15892197],\n",
       "       [259.07207202, 410.59186791,   7.10087481],\n",
       "       [237.00363221, 403.13045285,   5.41090515],\n",
       "       [267.02650283, 401.39109816,   6.40461919],\n",
       "       [244.95806303, 393.92968309,   4.71464953],\n",
       "       [272.33034887, 401.07252452,   5.88595127],\n",
       "       [250.26190907, 393.61110945,   4.19598161],\n",
       "       [264.03765242, 400.43727107,   6.60921997],\n",
       "       [241.96921261, 392.975856  ,   4.91925031],\n",
       "       [205.88797142, 316.31744249,   4.99666762],\n",
       "       [216.92219132, 320.04815002,   5.84165245],\n",
       "       [227.95641122, 323.77885755,   6.68663728],\n",
       "       [244.90359743, 370.35434498,   7.01015493],\n",
       "       [222.83515763, 362.89292992,   5.32018528],\n",
       "       [262.61347409, 408.62175992,   6.44166049],\n",
       "       [240.54503428, 401.16034485,   4.75169083],\n",
       "       [264.5796721 , 400.20479695,   6.60806163],\n",
       "       [242.51123229, 392.74338189,   4.91809197],\n",
       "       [270.09103545, 424.15765678,   6.48140045],\n",
       "       [248.02259565, 416.69624171,   4.7914308 ],\n",
       "       [241.51099509, 412.73537664,   5.18924143]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UfNWLcTtIjfE"
   },
   "outputs": [],
   "source": [
    "LR_mse = mean_squared_error(y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7Dg0jHVsItKH"
   },
   "outputs": [],
   "source": [
    "LR_rmse = np.sqrt(LR_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mp1oCKZIwON",
    "outputId": "18c5fc8d-cf9c-4df8-d4cf-ca4e64793f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) =  1123.0615194510735\n",
      "Root Mean Squared Error (RMSE) =  33.51211004176063\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error (MSE) = \",LR_mse)\n",
    "print(\"Root Mean Squared Error (RMSE) = \",LR_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNIhhjdBH4GJ"
   },
   "source": [
    "### KNeighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "K1acTIyjH1Cd"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "1j5nGMxRIAGZ",
    "outputId": "133be3e5-c94e-4c2b-fe0e-e6c04c042b32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_model = KNeighborsRegressor()\n",
    "# fit model\n",
    "KNN_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MK1InzMiIO-O"
   },
   "outputs": [],
   "source": [
    "KNN_predictions = KNN_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SdUjjjlhIUiT",
    "outputId": "853a3cb2-e7f4-4a51-f24e-947387e6cc0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[250.4 , 380.  ,   4.5 ],\n",
       "       [246.8 , 383.8 ,   4.18],\n",
       "       [227.52, 401.04,   7.24],\n",
       "       [225.28, 397.48,   7.06],\n",
       "       [247.92, 404.44,   6.14],\n",
       "       [231.08, 363.68,   4.72],\n",
       "       [222.18, 357.74,   7.26],\n",
       "       [224.74, 357.58,   6.38],\n",
       "       [245.78, 371.94,   6.4 ],\n",
       "       [218.94, 331.78,   4.54],\n",
       "       [243.8 , 394.8 ,   9.48],\n",
       "       [222.2 , 405.8 ,   6.96],\n",
       "       [248.4 , 446.4 ,   8.62],\n",
       "       [232.6 , 454.2 ,   7.26],\n",
       "       [243.8 , 394.8 ,   9.48],\n",
       "       [222.2 , 405.8 ,   6.96],\n",
       "       [259.8 , 400.4 ,   8.8 ],\n",
       "       [247.  , 408.8 ,   6.48],\n",
       "       [268.2 , 435.8 ,   4.98],\n",
       "       [265.2 , 436.8 ,   4.56],\n",
       "       [231.78, 321.74,   4.9 ],\n",
       "       [234.34, 321.58,   4.02],\n",
       "       [243.8 , 394.8 ,   9.48],\n",
       "       [222.2 , 405.8 ,   6.96],\n",
       "       [264.6 , 413.4 ,   9.6 ],\n",
       "       [232.4 , 412.8 ,   6.64],\n",
       "       [243.8 , 394.8 ,   9.48],\n",
       "       [222.2 , 405.8 ,   6.96],\n",
       "       [218.38, 343.94,   6.18],\n",
       "       [220.94, 343.78,   5.3 ],\n",
       "       [232.  , 426.8 ,   7.1 ],\n",
       "       [228.6 , 433.  ,   6.68],\n",
       "       [268.2 , 435.8 ,   4.98],\n",
       "       [265.2 , 436.8 ,   4.56],\n",
       "       [268.4 , 427.  ,   3.8 ],\n",
       "       [249.  , 386.4 ,   3.26],\n",
       "       [255.  , 416.4 ,   5.02],\n",
       "       [249.2 , 408.2 ,   5.52],\n",
       "       [237.4 , 377.2 ,   5.98],\n",
       "       [233.4 , 382.4 ,   5.66],\n",
       "       [219.46, 302.42,   4.94],\n",
       "       [215.46, 322.82,   6.22],\n",
       "       [234.06, 339.62,   6.18],\n",
       "       [264.6 , 413.4 ,   9.6 ],\n",
       "       [232.4 , 412.8 ,   6.64],\n",
       "       [255.8 , 378.8 ,   5.76],\n",
       "       [255.8 , 378.8 ,   5.76],\n",
       "       [251.4 , 390.  ,   5.98],\n",
       "       [240.4 , 382.  ,   5.64],\n",
       "       [245.8 , 365.8 ,   4.22],\n",
       "       [245.6 , 365.4 ,   4.34],\n",
       "       [255.8 , 378.8 ,   5.76]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "v4Q2Ur5MIWRm"
   },
   "outputs": [],
   "source": [
    "KNN_mse = mean_squared_error(y,KNN_predictions)\n",
    "KNN_rmse = np.sqrt(KNN_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfe7EfVOI-00",
    "outputId": "bc71e6f1-add1-4ac8-aa5e-ae78d3effce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) =  1188.3519076923073\n",
      "Root Mean Squared Error (RMSE) =  34.47248044008884\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error (MSE) = \",KNN_mse)\n",
    "print(\"Root Mean Squared Error (RMSE) = \",KNN_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEfMRE-1JGTW"
   },
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QQYzyN7_JAZu"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfQtI5MfJNhl",
    "outputId": "ba2948bb-1be4-48bb-817b-0f28e0d02260"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.450e+02, 4.200e+02, 5.900e+00],\n",
       "       [2.200e+02, 4.000e+02, 3.200e+00],\n",
       "       [2.320e+02, 4.150e+02, 8.000e+00],\n",
       "       [2.040e+02, 4.370e+02, 5.500e+00],\n",
       "       [2.800e+02, 4.720e+02, 7.800e+00],\n",
       "       [2.300e+02, 4.750e+02, 5.600e+00],\n",
       "       [2.470e+02, 4.250e+02, 9.400e+00],\n",
       "       [2.220e+02, 4.000e+02, 5.700e+00],\n",
       "       [1.900e+02, 3.230e+02, 6.700e+00],\n",
       "       [2.140e+02, 3.400e+02, 3.200e+00],\n",
       "       [2.870e+02, 4.750e+02, 1.090e+01],\n",
       "       [2.450e+02, 4.700e+02, 9.400e+00],\n",
       "       [2.380e+02, 4.640e+02, 1.010e+01],\n",
       "       [2.280e+02, 4.780e+02, 7.000e+00],\n",
       "       [2.640e+02, 4.510e+02, 8.600e+00],\n",
       "       [2.470e+02, 4.820e+02, 6.500e+00],\n",
       "       [3.180e+02, 4.500e+02, 8.600e+00],\n",
       "       [2.630e+02, 4.100e+02, 6.900e+00],\n",
       "       [2.700e+02, 4.500e+02, 6.600e+00],\n",
       "       [2.600e+02, 4.600e+02, 5.200e+00],\n",
       "       [3.070e+02, 4.240e+02, 3.000e+00],\n",
       "       [2.100e+02, 2.210e+02, 3.000e-01],\n",
       "       [2.480e+02, 3.860e+02, 8.600e+00],\n",
       "       [2.280e+02, 4.120e+02, 7.000e+00],\n",
       "       [2.690e+02, 4.180e+02, 7.800e+00],\n",
       "       [2.260e+02, 4.290e+02, 4.000e+00],\n",
       "       [2.350e+02, 3.890e+02, 7.200e+00],\n",
       "       [2.100e+02, 3.920e+02, 5.500e+00],\n",
       "       [2.410e+02, 3.990e+02, 6.500e+00],\n",
       "       [2.090e+02, 3.570e+02, 3.200e+00],\n",
       "       [2.250e+02, 3.640e+02, 6.500e+00],\n",
       "       [2.050e+02, 3.770e+02, 3.300e+00],\n",
       "       [2.650e+02, 4.400e+02, 4.700e+00],\n",
       "       [2.840e+02, 4.380e+02, 2.800e+00],\n",
       "       [2.750e+02, 4.000e+02, 1.600e+00],\n",
       "       [2.500e+02, 3.640e+02, 1.000e+00],\n",
       "       [2.800e+02, 4.550e+02, 8.100e+00],\n",
       "       [2.620e+02, 4.740e+02, 6.500e+00],\n",
       "       [2.620e+02, 3.910e+02, 5.600e+00],\n",
       "       [2.470e+02, 3.960e+02, 3.500e+00],\n",
       "       [2.214e+02, 3.104e+02, 6.700e+00],\n",
       "       [2.193e+02, 3.125e+02, 6.900e+00],\n",
       "       [2.326e+02, 3.282e+02, 7.600e+00],\n",
       "       [1.850e+02, 2.730e+02, 1.210e+01],\n",
       "       [1.810e+02, 2.730e+02, 6.400e+00],\n",
       "       [2.570e+02, 3.840e+02, 6.700e+00],\n",
       "       [2.560e+02, 3.820e+02, 7.300e+00],\n",
       "       [2.150e+02, 3.550e+02, 5.180e+00],\n",
       "       [2.150e+02, 3.580e+02, 7.020e+00],\n",
       "       [2.680e+02, 3.330e+02, 1.400e+00],\n",
       "       [2.390e+02, 2.920e+02, 3.900e+00],\n",
       "       [2.490e+02, 4.830e+02, 1.150e+01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DT_model = DecisionTreeRegressor()\n",
    "DT_model.fit(X, y)\n",
    "\n",
    "DT_predictions = DT_model.predict(X)\n",
    "DT_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sliwGh8uJdxJ"
   },
   "outputs": [],
   "source": [
    "DT_mse = mean_squared_error(y,DT_predictions)\n",
    "DT_rmse = np.sqrt(DT_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUKuJC0JJpJz",
    "outputId": "f91e45eb-97c6-4e8f-9be6-d149be07e7ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) =  0.0\n",
      "Root Mean Squared Error (RMSE) =  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error (MSE) = \",DT_mse)\n",
    "print(\"Root Mean Squared Error (RMSE) = \",DT_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxWn33V9mpLl"
   },
   "source": [
    "#### This is an overfitted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6MF2g35KBVU"
   },
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7JP1rY-iJqqn"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAFtRyIVLCvi",
    "outputId": "95b8e3ef-b473-47ba-f63f-61eabf1d10f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[247.766 , 410.162 ,   5.485 ],\n",
       "       [222.404 , 385.054 ,   3.625 ],\n",
       "       [230.48  , 417.41  ,   7.501 ],\n",
       "       [209.844 , 421.354 ,   5.33  ],\n",
       "       [267.02  , 456.81  ,   7.606 ],\n",
       "       [237.05  , 456.84  ,   6.212 ],\n",
       "       [241.67  , 413.17  ,   8.284 ],\n",
       "       [220.208 , 393.122 ,   5.511 ],\n",
       "       [213.52  , 364.07  ,   6.907 ],\n",
       "       [213.214 , 362.964 ,   4.679 ],\n",
       "       [269.93  , 456.37  ,   9.787 ],\n",
       "       [246.11  , 455.48  ,   8.792 ],\n",
       "       [245.2   , 455.96  ,   9.26  ],\n",
       "       [231.21  , 470.43  ,   7.137 ],\n",
       "       [259.57  , 451.72  ,   8.689 ],\n",
       "       [246.43  , 468.01  ,   6.93  ],\n",
       "       [298.84  , 440.52  ,   8.136 ],\n",
       "       [263.83  , 425.56  ,   6.754 ],\n",
       "       [269.22  , 444.3   ,   6.28  ],\n",
       "       [258.39  , 449.02  ,   4.9094],\n",
       "       [273.31  , 371.2   ,   2.932 ],\n",
       "       [226.96  , 309.04  ,   2.163 ],\n",
       "       [247.47  , 401.27  ,   8.294 ],\n",
       "       [233.71  , 415.14  ,   7.045 ],\n",
       "       [268.99  , 427.65  ,   7.469 ],\n",
       "       [241.84  , 429.51  ,   5.281 ],\n",
       "       [240.04  , 406.7   ,   7.614 ],\n",
       "       [219.95  , 408.38  ,   6.347 ],\n",
       "       [246.936 , 397.472 ,   5.678 ],\n",
       "       [214.544 , 357.254 ,   3.361 ],\n",
       "       [237.97  , 377.37  ,   5.697 ],\n",
       "       [211.36  , 370.13  ,   3.835 ],\n",
       "       [268.23  , 435.58  ,   4.5918],\n",
       "       [270.83  , 439.47  ,   3.7872],\n",
       "       [265.44  , 391.24  ,   2.0204],\n",
       "       [253.7   , 376.87  ,   1.998 ],\n",
       "       [273.59  , 448.43  ,   6.97  ],\n",
       "       [262.46  , 458.74  ,   6.648 ],\n",
       "       [258.01  , 394.91  ,   5.3756],\n",
       "       [248.38  , 397.8   ,   4.0862],\n",
       "       [220.925 , 314.647 ,   6.585 ],\n",
       "       [222.593 , 320.027 ,   7.088 ],\n",
       "       [228.333 , 330.229 ,   7.323 ],\n",
       "       [201.786 , 302.822 ,   9.84  ],\n",
       "       [192.11  , 300.16  ,   7.21  ],\n",
       "       [257.    , 387.38  ,   6.534 ],\n",
       "       [253.23  , 393.17  ,   6.9   ],\n",
       "       [228.34  , 365.85  ,   5.0338],\n",
       "       [222.06  , 364.61  ,   6.0198],\n",
       "       [261.02  , 338.88  ,   2.853 ],\n",
       "       [245.68  , 327.28  ,   4.193 ],\n",
       "       [244.32  , 452.69  ,   9.026 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "RF_model = RandomForestRegressor()\n",
    "RF_model.fit(X, y)\n",
    "\n",
    "RF_predictions = RF_model.predict(X)\n",
    "RF_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "HbTL_3T8LSR2"
   },
   "outputs": [],
   "source": [
    "RF_mse = mean_squared_error(y,RF_predictions)\n",
    "RF_rmse = np.sqrt(RF_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyaTxnhQLkP3",
    "outputId": "9dd4c7e3-38c5-4a8c-bf42-678655146809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) =  168.02329514666675\n",
      "Root Mean Squared Error (RMSE) =  12.962379995458656\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error (MSE) = \",RF_mse)\n",
    "print(\"Root Mean Squared Error (RMSE) = \",RF_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-m6e-LlOzoA"
   },
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yVY3AJkJLl8z"
   },
   "outputs": [],
   "source": [
    "# evaluate multioutput regression model with k-fold cross-validation\n",
    "from numpy import absolute,mean,std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PN7hglgnO-I7",
    "outputId": "d3818ee6-2d99-44f7-dc8d-e16d0bad11de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 19.805 (6.293)\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "n_scores = cross_val_score(rf_model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "n_scores = absolute(n_scores)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJQFTiEYQ-bg"
   },
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "kWfVG1v4Q8Io"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "EAps9TmzRFCO"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.05,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1risoIgcRX9f",
    "outputId": "44304e6b-3929-4c33-e381-eff5a22e5cdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49, 5), (3, 5), (49, 3), (3, 3))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "850uSoG7PadH",
    "outputId": "9a175b33-153d-40a1-aada-55262d9399aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestRegressor(random_state=0),\n",
       "             param_grid={&#x27;max_depth&#x27;: [4, 6, 7, 8, 9, 15, 19, 21, 25, 30, 35,\n",
       "                                       40],\n",
       "                         &#x27;n_estimators&#x27;: [99, 100, 125, 130, 135, 140, 145, 149,\n",
       "                                          150, 155, 160, 165, 170, 199, 200,\n",
       "                                          249, 250, 299, 300]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestRegressor(random_state=0),\n",
       "             param_grid={&#x27;max_depth&#x27;: [4, 6, 7, 8, 9, 15, 19, 21, 25, 30, 35,\n",
       "                                       40],\n",
       "                         &#x27;n_estimators&#x27;: [99, 100, 125, 130, 135, 140, 145, 149,\n",
       "                                          150, 155, 160, 165, 170, 199, 200,\n",
       "                                          249, 250, 299, 300]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(random_state=0),\n",
       "             param_grid={'max_depth': [4, 6, 7, 8, 9, 15, 19, 21, 25, 30, 35,\n",
       "                                       40],\n",
       "                         'n_estimators': [99, 100, 125, 130, 135, 140, 145, 149,\n",
       "                                          150, 155, 160, 165, 170, 199, 200,\n",
       "                                          249, 250, 299, 300]})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [99,100,125,130,135,140,145,149,150,155,160,165,170,199,200,249,250,299,300],\n",
    "    'max_depth': [4,6,7,8,9,15,19,21,25,30,35,40],\n",
    "}\n",
    "regr = RandomForestRegressor(random_state=0)\n",
    "\n",
    "clf = GridSearchCV(regr, parameters)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xuwfknzRh7D",
    "outputId": "5d7a3301-b941-4f70-c848-e1824a4b6ea6"
   },
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDobm41mRwH7"
   },
   "outputs": [],
   "source": [
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACNW7CI7R0fE"
   },
   "outputs": [],
   "source": [
    "train_mse = mean_squared_error(y_train,train_predictions)\n",
    "test_mse = mean_squared_error(y_test,test_predictions)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXEzQ0RuSoo-",
    "outputId": "749bb98a-35ff-43ba-937d-ea52e2448a43"
   },
   "outputs": [],
   "source": [
    "train_mse,train_rmse, test_mse,test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yb7oThoIl4Pg",
    "outputId": "0bc36790-83e6-4470-fd13-44cad02115ef"
   },
   "outputs": [],
   "source": [
    "print(\"Train - Mean Squared Error (MSE) = \",train_mse)\n",
    "print(\"Train - Root Mean Squared Error (RMSE) = \",train_rmse)\n",
    "\n",
    "print(\"Test - Mean Squared Error (MSE) = \",test_mse)\n",
    "print(\"Test - Root Mean Squared Error (RMSE) = \",test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZBzx0TwmJPu"
   },
   "source": [
    "### Random Forest is the best model so far with test rmse of 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvSq4JKcY9qq"
   },
   "source": [
    "### Keras Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "id": "jrm6LdS3ZCMe"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=5, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(32, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(64, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(128, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(256, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(512, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(512, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(512, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(512, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "\n",
    "model.add(Dense(512, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(512, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(512, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(512, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(512, kernel_initializer='he_uniform', activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(256, kernel_initializer='he_uniform', activation=\"relu\"))\n",
    "model.add(Dense(256, kernel_initializer='he_uniform', activation=\"relu\"))\n",
    "model.add(Dense(128, kernel_initializer='he_uniform', activation=\"relu\"))\n",
    "model.add(Dense(64, kernel_initializer='he_uniform', activation=\"relu\"))\n",
    "model.add(Dense(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMuEETjzSu8B",
    "outputId": "22a4182c-2ada-4bc9-f151-5f1f2461d55e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_490 (Dense)           (None, 25)                150       \n",
      "                                                                 \n",
      " dense_491 (Dense)           (None, 32)                832       \n",
      "                                                                 \n",
      " dense_492 (Dense)           (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_493 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_494 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_495 (Dense)           (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_496 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_497 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_498 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_499 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_500 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_501 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_502 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_503 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_504 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_505 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_506 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_507 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_508 (Dense)           (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,515,737\n",
      "Trainable params: 2,515,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "2/2 [==============================] - 3s 35ms/step - loss: 320974.9375\n",
      "Epoch 2/400\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 75137.5234\n",
      "Epoch 3/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 111000.7969\n",
      "Epoch 4/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 11548.0381\n",
      "Epoch 5/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 10332.8516\n",
      "Epoch 6/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 7153.6875\n",
      "Epoch 7/400\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 8007.7104\n",
      "Epoch 8/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6555.4307\n",
      "Epoch 9/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 5482.6143\n",
      "Epoch 10/400\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 4748.6318\n",
      "Epoch 11/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4055.1816\n",
      "Epoch 12/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 4301.2090\n",
      "Epoch 13/400\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3862.2761\n",
      "Epoch 14/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 4011.9343\n",
      "Epoch 15/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4041.5105\n",
      "Epoch 16/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 4369.8271\n",
      "Epoch 17/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3764.7908\n",
      "Epoch 18/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4278.9141\n",
      "Epoch 19/400\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 4273.7251\n",
      "Epoch 20/400\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3256.1533\n",
      "Epoch 21/400\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3292.0410\n",
      "Epoch 22/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3449.1218\n",
      "Epoch 23/400\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3157.9023\n",
      "Epoch 24/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3015.9648\n",
      "Epoch 25/400\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2795.2227\n",
      "Epoch 26/400\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 2627.3918\n",
      "Epoch 27/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 2692.0632\n",
      "Epoch 28/400\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2891.1470\n",
      "Epoch 29/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 2600.2673\n",
      "Epoch 30/400\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 2662.5859\n",
      "Epoch 31/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 2508.4648\n",
      "Epoch 32/400\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3130.5969\n",
      "Epoch 33/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 2556.4607\n",
      "Epoch 34/400\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3108.4873\n",
      "Epoch 35/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 2912.4158\n",
      "Epoch 36/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 2178.7290\n",
      "Epoch 37/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 2152.8184\n",
      "Epoch 38/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 2225.9851\n",
      "Epoch 39/400\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2014.8772\n",
      "Epoch 40/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1924.8750\n",
      "Epoch 41/400\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1732.7634\n",
      "Epoch 42/400\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1630.2124\n",
      "Epoch 43/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1614.8125\n",
      "Epoch 44/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1652.9337\n",
      "Epoch 45/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1522.3108\n",
      "Epoch 46/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1644.1957\n",
      "Epoch 47/400\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1485.9272\n",
      "Epoch 48/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1903.4933\n",
      "Epoch 49/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2116.9185\n",
      "Epoch 50/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3616.2083\n",
      "Epoch 51/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2867.4705\n",
      "Epoch 52/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1668.6885\n",
      "Epoch 53/400\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1692.0833\n",
      "Epoch 54/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1432.4705\n",
      "Epoch 55/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1407.1384\n",
      "Epoch 56/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1286.1946\n",
      "Epoch 57/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1314.0193\n",
      "Epoch 58/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1472.1415\n",
      "Epoch 59/400\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2106.8853\n",
      "Epoch 60/400\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1770.8369\n",
      "Epoch 61/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1282.5858\n",
      "Epoch 62/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1522.1746\n",
      "Epoch 63/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1720.2733\n",
      "Epoch 64/400\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1257.9515\n",
      "Epoch 65/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 997.2708\n",
      "Epoch 66/400\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1122.4249\n",
      "Epoch 67/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1125.4021\n",
      "Epoch 68/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1046.3418\n",
      "Epoch 69/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1064.3466\n",
      "Epoch 70/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 933.7803\n",
      "Epoch 71/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 948.3919\n",
      "Epoch 72/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1051.2275\n",
      "Epoch 73/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1376.4791\n",
      "Epoch 74/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1437.8898\n",
      "Epoch 75/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1264.1827\n",
      "Epoch 76/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1867.4672\n",
      "Epoch 77/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1617.3636\n",
      "Epoch 78/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 926.6789\n",
      "Epoch 79/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1014.8284\n",
      "Epoch 80/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1155.0905\n",
      "Epoch 81/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1157.6392\n",
      "Epoch 82/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1086.9468\n",
      "Epoch 83/400\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 780.6190\n",
      "Epoch 84/400\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1070.2183\n",
      "Epoch 85/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 740.1005\n",
      "Epoch 86/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 810.8555\n",
      "Epoch 87/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 690.0821\n",
      "Epoch 88/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1390.2056\n",
      "Epoch 89/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1534.4474\n",
      "Epoch 90/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2404.2305\n",
      "Epoch 91/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2626.6833\n",
      "Epoch 92/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 2936.0383\n",
      "Epoch 93/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1907.4363\n",
      "Epoch 94/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1371.7334\n",
      "Epoch 95/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1831.8351\n",
      "Epoch 96/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2063.9919\n",
      "Epoch 97/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2027.5150\n",
      "Epoch 98/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1824.8600\n",
      "Epoch 99/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1299.4447\n",
      "Epoch 100/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1571.2385\n",
      "Epoch 101/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1066.7784\n",
      "Epoch 102/400\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 735.9713\n",
      "Epoch 103/400\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 864.3758\n",
      "Epoch 104/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 892.8029\n",
      "Epoch 105/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 688.0775\n",
      "Epoch 106/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 545.7519\n",
      "Epoch 107/400\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 731.0289\n",
      "Epoch 108/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 578.3480\n",
      "Epoch 109/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 579.3972\n",
      "Epoch 110/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 584.3955\n",
      "Epoch 111/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 548.9097\n",
      "Epoch 112/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 494.8600\n",
      "Epoch 113/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 531.7625\n",
      "Epoch 114/400\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 560.2731\n",
      "Epoch 115/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 502.3900\n",
      "Epoch 116/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 519.5430\n",
      "Epoch 117/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 406.0586\n",
      "Epoch 118/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 406.0890\n",
      "Epoch 119/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 531.0159\n",
      "Epoch 120/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 487.2719\n",
      "Epoch 121/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 389.1818\n",
      "Epoch 122/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 886.3156\n",
      "Epoch 123/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 429.0270\n",
      "Epoch 124/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 368.2343\n",
      "Epoch 125/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 298.6062\n",
      "Epoch 126/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 430.1510\n",
      "Epoch 127/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 513.6531\n",
      "Epoch 128/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 551.3990\n",
      "Epoch 129/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 281.4892\n",
      "Epoch 130/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 340.9416\n",
      "Epoch 131/400\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 501.4876\n",
      "Epoch 132/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 402.7426\n",
      "Epoch 133/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 667.0193\n",
      "Epoch 134/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 417.6992\n",
      "Epoch 135/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 390.6760\n",
      "Epoch 136/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 393.2740\n",
      "Epoch 137/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 393.8181\n",
      "Epoch 138/400\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 401.6989\n",
      "Epoch 139/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 580.6495\n",
      "Epoch 140/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 927.8430\n",
      "Epoch 141/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 780.8745\n",
      "Epoch 142/400\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 682.1108\n",
      "Epoch 143/400\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 644.6455\n",
      "Epoch 144/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 629.5442\n",
      "Epoch 145/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 690.8747\n",
      "Epoch 146/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 490.2834\n",
      "Epoch 147/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 594.5308\n",
      "Epoch 148/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 575.2380\n",
      "Epoch 149/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 586.9653\n",
      "Epoch 150/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1015.7406\n",
      "Epoch 151/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1309.1720\n",
      "Epoch 152/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1624.7734\n",
      "Epoch 153/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 901.5612\n",
      "Epoch 154/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 855.9478\n",
      "Epoch 155/400\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1287.2882\n",
      "Epoch 156/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 796.6519\n",
      "Epoch 157/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 636.3515\n",
      "Epoch 158/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 544.3981\n",
      "Epoch 159/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 395.5755\n",
      "Epoch 160/400\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 353.8873\n",
      "Epoch 161/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 475.6370\n",
      "Epoch 162/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 331.3952\n",
      "Epoch 163/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 259.7401\n",
      "Epoch 164/400\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 220.6812\n",
      "Epoch 165/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 156.1451\n",
      "Epoch 166/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 201.6534\n",
      "Epoch 167/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 157.7845\n",
      "Epoch 168/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 125.2105\n",
      "Epoch 169/400\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 137.4007\n",
      "Epoch 170/400\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 109.3559\n",
      "Epoch 171/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 170.9390\n",
      "Epoch 172/400\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 159.1963\n",
      "Epoch 173/400\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 124.8014\n",
      "Epoch 174/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 133.7787\n",
      "Epoch 175/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 150.6202\n",
      "Epoch 176/400\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 129.2721\n",
      "Epoch 177/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 86.3534\n",
      "Epoch 178/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 114.4368\n",
      "Epoch 179/400\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 122.2340\n",
      "Epoch 180/400\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 117.4917\n",
      "Epoch 181/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 121.7778\n",
      "Epoch 182/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 294.1544\n",
      "Epoch 183/400\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 785.2617\n",
      "Epoch 184/400\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 496.5915\n",
      "Epoch 185/400\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 288.2350\n",
      "Epoch 186/400\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 318.3554\n",
      "Epoch 187/400\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 160.3278\n",
      "Epoch 188/400\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 125.8419\n",
      "Epoch 189/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 101.1260\n",
      "Epoch 190/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 92.4376\n",
      "Epoch 191/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 102.1561\n",
      "Epoch 192/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 126.3150\n",
      "Epoch 193/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 151.6680\n",
      "Epoch 194/400\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 143.2431\n",
      "Epoch 195/400\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 111.4699\n",
      "Epoch 196/400\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 103.3160\n",
      "Epoch 197/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 90.8130\n",
      "Epoch 198/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 61.0428\n",
      "Epoch 199/400\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 48.6394\n",
      "Epoch 200/400\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 56.3499\n",
      "Epoch 201/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 63.7633\n",
      "Epoch 202/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 50.5459\n",
      "Epoch 203/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 51.1128\n",
      "Epoch 204/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 49.2878\n",
      "Epoch 205/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 65.6592\n",
      "Epoch 206/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 47.4043\n",
      "Epoch 207/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 37.9969\n",
      "Epoch 208/400\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 40.8059\n",
      "Epoch 209/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 46.5210\n",
      "Epoch 210/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 59.5088\n",
      "Epoch 211/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 76.3088\n",
      "Epoch 212/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 102.8553\n",
      "Epoch 213/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 88.0875\n",
      "Epoch 214/400\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 164.5664\n",
      "Epoch 215/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 286.6682\n",
      "Epoch 216/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 219.6958\n",
      "Epoch 217/400\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 211.3820\n",
      "Epoch 218/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 179.0818\n",
      "Epoch 219/400\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 154.7391\n",
      "Epoch 220/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 170.8904\n",
      "Epoch 221/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 213.8715\n",
      "Epoch 222/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 285.9641\n",
      "Epoch 223/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 273.9686\n",
      "Epoch 224/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 154.7093\n",
      "Epoch 225/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 162.9622\n",
      "Epoch 226/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 87.2303\n",
      "Epoch 227/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 153.4536\n",
      "Epoch 228/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 96.2419\n",
      "Epoch 229/400\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 107.6416\n",
      "Epoch 230/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 116.1709\n",
      "Epoch 231/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 99.2952\n",
      "Epoch 232/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 122.9946\n",
      "Epoch 233/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 67.9236\n",
      "Epoch 234/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 62.9327\n",
      "Epoch 235/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 79.4784\n",
      "Epoch 236/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 63.3874\n",
      "Epoch 237/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 78.6945\n",
      "Epoch 238/400\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 52.4112\n",
      "Epoch 239/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 84.3627\n",
      "Epoch 240/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 78.4346\n",
      "Epoch 241/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 100.8206\n",
      "Epoch 242/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 219.3074\n",
      "Epoch 243/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 329.8251\n",
      "Epoch 244/400\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 308.8553\n",
      "Epoch 245/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 210.8559\n",
      "Epoch 246/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 281.6929\n",
      "Epoch 247/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 258.4550\n",
      "Epoch 248/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 478.7931\n",
      "Epoch 249/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 315.9981\n",
      "Epoch 250/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 382.9674\n",
      "Epoch 251/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 461.8961\n",
      "Epoch 252/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 503.2993\n",
      "Epoch 253/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 438.2353\n",
      "Epoch 254/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 545.8960\n",
      "Epoch 255/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 757.0228\n",
      "Epoch 256/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 747.2533\n",
      "Epoch 257/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 653.5827\n",
      "Epoch 258/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 536.0355\n",
      "Epoch 259/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 605.6673\n",
      "Epoch 260/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 438.4241\n",
      "Epoch 261/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 292.5549\n",
      "Epoch 262/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 728.1881\n",
      "Epoch 263/400\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 578.0041\n",
      "Epoch 264/400\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 525.9336\n",
      "Epoch 265/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 413.7595\n",
      "Epoch 266/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 216.5519\n",
      "Epoch 267/400\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 290.1096\n",
      "Epoch 268/400\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 210.4384\n",
      "Epoch 269/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 265.1577\n",
      "Epoch 270/400\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 289.5620\n",
      "Epoch 271/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 429.3789\n",
      "Epoch 272/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 460.8116\n",
      "Epoch 273/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 386.8669\n",
      "Epoch 274/400\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 255.4315\n",
      "Epoch 275/400\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 246.3608\n",
      "Epoch 276/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 333.5345\n",
      "Epoch 277/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 219.1924\n",
      "Epoch 278/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 321.8708\n",
      "Epoch 279/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 183.2903\n",
      "Epoch 280/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 159.5007\n",
      "Epoch 281/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 97.5011\n",
      "Epoch 282/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 105.6504\n",
      "Epoch 283/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 101.6197\n",
      "Epoch 284/400\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 104.4274\n",
      "Epoch 285/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 84.0147\n",
      "Epoch 286/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 57.3820\n",
      "Epoch 287/400\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 61.1291\n",
      "Epoch 288/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 56.5356\n",
      "Epoch 289/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 81.6642\n",
      "Epoch 290/400\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 75.0038\n",
      "Epoch 291/400\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 69.9239\n",
      "Epoch 292/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 84.7636\n",
      "Epoch 293/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 76.7102\n",
      "Epoch 294/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 57.5986\n",
      "Epoch 295/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 44.5751\n",
      "Epoch 296/400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 52.2285\n",
      "Epoch 297/400\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 49.9169\n",
      "Epoch 298/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 33.1994\n",
      "Epoch 299/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 42.0374\n",
      "Epoch 300/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 79.1466\n",
      "Epoch 301/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 117.4118\n",
      "Epoch 302/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 92.3656\n",
      "Epoch 303/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 101.4608\n",
      "Epoch 304/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 113.4478\n",
      "Epoch 305/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 77.9471\n",
      "Epoch 306/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 50.7993\n",
      "Epoch 307/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 38.5447\n",
      "Epoch 308/400\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 28.3154\n",
      "Epoch 309/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 68.3219\n",
      "Epoch 310/400\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 62.4129\n",
      "Epoch 311/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 73.5529\n",
      "Epoch 312/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 71.8002\n",
      "Epoch 313/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 70.7650\n",
      "Epoch 314/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 55.9141\n",
      "Epoch 315/400\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 45.1830\n",
      "Epoch 316/400\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 36.9943\n",
      "Epoch 317/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 43.0871\n",
      "Epoch 318/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 32.0850\n",
      "Epoch 319/400\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 34.7924\n",
      "Epoch 320/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 32.0158\n",
      "Epoch 321/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 37.3337\n",
      "Epoch 322/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 20.7704\n",
      "Epoch 323/400\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 37.7846\n",
      "Epoch 324/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 18.8114\n",
      "Epoch 325/400\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 17.7426\n",
      "Epoch 326/400\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 33.4062\n",
      "Epoch 327/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 22.4010\n",
      "Epoch 328/400\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 20.3506\n",
      "Epoch 329/400\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 34.5764\n",
      "Epoch 330/400\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 34.1487\n",
      "Epoch 331/400\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 42.1121\n",
      "Epoch 332/400\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 33.8797\n",
      "Epoch 333/400\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 25.1674\n",
      "Epoch 334/400\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 29.7257\n",
      "Epoch 335/400\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 53.5671\n",
      "Epoch 336/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 41.9893\n",
      "Epoch 337/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 15.7027\n",
      "Epoch 338/400\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 39.6842\n",
      "Epoch 339/400\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 28.3422\n",
      "Epoch 340/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 22.9788\n",
      "Epoch 341/400\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 31.9000\n",
      "Epoch 342/400\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 58.4448\n",
      "Epoch 343/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 33.3688\n",
      "Epoch 344/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 69.9789\n",
      "Epoch 345/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 37.2525\n",
      "Epoch 346/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 54.6439\n",
      "Epoch 347/400\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 65.4616\n",
      "Epoch 348/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 136.1583\n",
      "Epoch 349/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 110.3161\n",
      "Epoch 350/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 133.5587\n",
      "Epoch 351/400\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 130.6893\n",
      "Epoch 352/400\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 168.7009\n",
      "Epoch 353/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 351.2678\n",
      "Epoch 354/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 239.4479\n",
      "Epoch 355/400\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 179.9540\n",
      "Epoch 356/400\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 145.7516\n",
      "Epoch 357/400\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 104.2982\n",
      "Epoch 358/400\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 62.9391\n",
      "Epoch 359/400\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 54.4342\n",
      "Epoch 360/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 65.6348\n",
      "Epoch 361/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 76.6989\n",
      "Epoch 362/400\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 94.4106\n",
      "Epoch 363/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 87.1756\n",
      "Epoch 364/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 82.9192\n",
      "Epoch 365/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 45.5653\n",
      "Epoch 366/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 37.3644\n",
      "Epoch 367/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 35.2630\n",
      "Epoch 368/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 25.7178\n",
      "Epoch 369/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 24.6008\n",
      "Epoch 370/400\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 26.7410\n",
      "Epoch 371/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 28.1416\n",
      "Epoch 372/400\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 23.7503\n",
      "Epoch 373/400\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 35.1690\n",
      "Epoch 374/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 28.3138\n",
      "Epoch 375/400\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 26.0779\n",
      "Epoch 376/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 12.5543\n",
      "Epoch 377/400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 40.1983\n",
      "Epoch 378/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 44.1078\n",
      "Epoch 379/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 86.4873\n",
      "Epoch 380/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 63.8904\n",
      "Epoch 381/400\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 72.0578\n",
      "Epoch 382/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 73.2305\n",
      "Epoch 383/400\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 125.1493\n",
      "Epoch 384/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 109.4053\n",
      "Epoch 385/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 103.7616\n",
      "Epoch 386/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 125.9119\n",
      "Epoch 387/400\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 114.6142\n",
      "Epoch 388/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 92.2054\n",
      "Epoch 389/400\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 194.9475\n",
      "Epoch 390/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 277.7065\n",
      "Epoch 391/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 178.7204\n",
      "Epoch 392/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 158.2072\n",
      "Epoch 393/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 123.6188\n",
      "Epoch 394/400\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 105.0398\n",
      "Epoch 395/400\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 83.8092\n",
      "Epoch 396/400\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 84.1485\n",
      "Epoch 397/400\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 105.1607\n",
      "Epoch 398/400\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 61.6028\n",
      "Epoch 399/400\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 72.3701\n",
      "Epoch 400/400\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 42.2215\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss ='mse', optimizer = 'adam')\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, verbose = 'auto',epochs = 400)\n",
    "# from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hn-AlJQSZbYS",
    "outputId": "fb4d997b-6ea8-4d1c-ec69-cec437b465b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 182ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "id": "JpQHTIetZ5XO"
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test,y_pred)\n",
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9tC34Duawsn",
    "outputId": "946521bb-0b5e-4f51-9c95-adda1bd03b0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14663.022919522171, 121.09096960352647)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mean Squared Error (MSE) = \",mse)\n",
    "print(\"Root Mean Squared Error (RMSE) = \",rmse)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
